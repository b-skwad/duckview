{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"DUCKView Please pull up a chair and join me at the coding table, where there is, hopefully, mighty fine code, and mighty fine people to write it.","title":"Home"},{"location":"#duckview","text":"Please pull up a chair and join me at the coding table, where there is, hopefully, mighty fine code, and mighty fine people to write it.","title":"DUCKView"},{"location":"prfaq/","text":"Press Release The storage infrastructure that supports the Devolo requires monitoring, which led the purchasing of SANView. This tool, is not giving he storge team the level of control and detail of the management and monitoring of their devices, as such they have decided to implement DUCKView . LThe advantages of this project over SANView is the level of control over data gathered, and customisation of how reporting can and will be achieved. The Storage team will overcome the cons of the existing system by working to deliver an reporting tool that will: ingest the captured operational information of an existing device process the information extracting key data save this data in a database incorporate the saved data into standard reports that will allow for system health checks in a structured and repeatable manner compare new data against historical data and display differences. FAQ What are the basic components of the system? The basic components of the system are, a RESTful API call/parser to a target device, a state database , and a reporting engine . These components are all provided by the Devolo Storage Team/ psmware ltd. What is the RESTful API call/parser? Each device managed byt the Storage Team provides a RESTful API to allow the device to be interrogated for information. These APIs will be accessed to gather operational information about each device. The responses sent by each device will be parsed to glean the required operational data, ready for importing into the state database . What is the state database? The state database is a source of record for the operational state of the storage devices as captured. This allows for daily operation health check reporting, and for the configuration drift reporting, when compared against the historical data. The data model must be able to maintain historical state for specific settings that will apply to all devices. What is the reporting engine? The reporting engine will be an automated ETL that will process new entries into the state database, and build operational report roll-up data to be used by daily health-check reporting. And report where operational data has changed from previously captured data. I.e. a new disk is added to a host an SVC, or a new port is active on a fabric switch. Automation Workflows How are the basic workflows organised? Each workflow stage will be activated via cron tasks Capture make a GET call to REST API of a device gather the output of the response parse the output, and store data in the loading tables of the state database Processing Start ETL process to extract data from loading tables process loading tables build roll-up reporting tables for health check analysis build configuration change tables for reporting devices changes clear loading tables once complete Reporting Send health-chek reports to required team Send configuration drift reports to required team Repository GitHub Development Environment Self Contained Dev Environment(SCDE) Environment Variables TBD Database Configuration Deploy State Database on MySQL","title":"Press release/FAQ"},{"location":"prfaq/#press-release","text":"The storage infrastructure that supports the Devolo requires monitoring, which led the purchasing of SANView. This tool, is not giving he storge team the level of control and detail of the management and monitoring of their devices, as such they have decided to implement DUCKView . LThe advantages of this project over SANView is the level of control over data gathered, and customisation of how reporting can and will be achieved. The Storage team will overcome the cons of the existing system by working to deliver an reporting tool that will: ingest the captured operational information of an existing device process the information extracting key data save this data in a database incorporate the saved data into standard reports that will allow for system health checks in a structured and repeatable manner compare new data against historical data and display differences.","title":"Press Release"},{"location":"prfaq/#faq","text":"","title":"FAQ"},{"location":"prfaq/#what-are-the-basic-components-of-the-system","text":"The basic components of the system are, a RESTful API call/parser to a target device, a state database , and a reporting engine . These components are all provided by the Devolo Storage Team/ psmware ltd.","title":"What are the basic components of the system?"},{"location":"prfaq/#what-is-the-restful-api-callparser","text":"Each device managed byt the Storage Team provides a RESTful API to allow the device to be interrogated for information. These APIs will be accessed to gather operational information about each device. The responses sent by each device will be parsed to glean the required operational data, ready for importing into the state database .","title":"What is the RESTful API call/parser?"},{"location":"prfaq/#what-is-the-state-database","text":"The state database is a source of record for the operational state of the storage devices as captured. This allows for daily operation health check reporting, and for the configuration drift reporting, when compared against the historical data. The data model must be able to maintain historical state for specific settings that will apply to all devices.","title":"What is the state database?"},{"location":"prfaq/#what-is-the-reporting-engine","text":"The reporting engine will be an automated ETL that will process new entries into the state database, and build operational report roll-up data to be used by daily health-check reporting. And report where operational data has changed from previously captured data. I.e. a new disk is added to a host an SVC, or a new port is active on a fabric switch.","title":"What is the reporting engine?"},{"location":"prfaq/#automation-workflows","text":"How are the basic workflows organised? Each workflow stage will be activated via cron tasks","title":"Automation Workflows"},{"location":"prfaq/#capture","text":"make a GET call to REST API of a device gather the output of the response parse the output, and store data in the loading tables of the state database","title":"Capture"},{"location":"prfaq/#processing","text":"Start ETL process to extract data from loading tables process loading tables build roll-up reporting tables for health check analysis build configuration change tables for reporting devices changes clear loading tables once complete","title":"Processing"},{"location":"prfaq/#reporting","text":"Send health-chek reports to required team Send configuration drift reports to required team","title":"Reporting"},{"location":"prfaq/#repository","text":"GitHub","title":"Repository"},{"location":"prfaq/#development-environment","text":"Self Contained Dev Environment(SCDE)","title":"Development Environment"},{"location":"prfaq/#environment-variables","text":"TBD","title":"Environment Variables"},{"location":"prfaq/#database-configuration","text":"Deploy State Database on MySQL","title":"Database Configuration"},{"location":"cdf/docker-desktop/","text":"Installing Docker Desktop Go to the Docker for Windows Download page and Click the Get Docker button Double-click the downloaded Docker Desktop Installer.exe to run the installer. Follow the instructions on the installation wizard to authorize the installer and proceed with the install. When the installation is successful, click Close to complete the installation process. If your admin account is different to your user account, you must add the user to the docker-users group. Run Computer Management as an administrator and navigate to Local Users and Groups > Groups > docker-users . Right-click to add the user to the group. Log out and log back in for the changes to take effect.","title":"Docker Desktop"},{"location":"cdf/docker-desktop/#installing-docker-desktop","text":"Go to the Docker for Windows Download page and Click the Get Docker button Double-click the downloaded Docker Desktop Installer.exe to run the installer. Follow the instructions on the installation wizard to authorize the installer and proceed with the install. When the installation is successful, click Close to complete the installation process. If your admin account is different to your user account, you must add the user to the docker-users group. Run Computer Management as an administrator and navigate to Local Users and Groups > Groups > docker-users . Right-click to add the user to the group. Log out and log back in for the changes to take effect.","title":"Installing Docker Desktop"},{"location":"cdf/gpg-and-git/","text":"Configuring git to use your GPG key and credentials Open a new Ubuntu 20.04 Terminal Window, paste the command beginning with gpg below to list your gpg key, which will be used to sign your commits. me@my-pc:~$ gpg --list-secret-keys --keyid-format LONG /home/devops/.gnupg/pubring.kbx ------------------------------- sec rsa4096/A9E3031D40E7A31F 2021 -06-03 [ SC ] 71859D719307C206B6936735A9E3031D40E7A31F uid [ ultimate ] ~Your Name~ ( enter comment here ) ~your email address~ ssb rsa4096/B8239EB7C4286DAB 2021 -06-03 [ E ] me@my-pc:~$ We will be using the key displayed to configure git, here using the example key above A9E3031D40E7A31F taken from the 4 th line: sec rsa4096/A9E3031D40E7A31F 2021-06-03 [SC] Enter the following commands, substituting your name , email address , and gpg signingkey. me@my-pc:~$ git config --global gpg.program gpg me@my-pc:~$ git config --global commit.gpgsign true me@my-pc:~$ git config --global user.signingkey A9E3031D40E7A31F me@my-pc:~$ git config --global user.name \"~Your Name~\" me@my-pc:~$ git config --global user.email ~your email address~ me@my-pc:~$ Now verify that the config is correct, by typing cat ~/.gitconfig: You should see something similar to below, but with your credentials. me@my-pc:~$ cat ~/.gitconfig [ gpg ] program = gpg [ commit ] gpgsign = true [ user ] signingkey = A9E3031D40E7A31F name = ~Your Name~ email = ~your email address~ me@my-pc:~$","title":"Git on Ubuntu"},{"location":"cdf/gpg-and-git/#configuring-git-to-use-your-gpg-key-and-credentials","text":"Open a new Ubuntu 20.04 Terminal Window, paste the command beginning with gpg below to list your gpg key, which will be used to sign your commits. me@my-pc:~$ gpg --list-secret-keys --keyid-format LONG /home/devops/.gnupg/pubring.kbx ------------------------------- sec rsa4096/A9E3031D40E7A31F 2021 -06-03 [ SC ] 71859D719307C206B6936735A9E3031D40E7A31F uid [ ultimate ] ~Your Name~ ( enter comment here ) ~your email address~ ssb rsa4096/B8239EB7C4286DAB 2021 -06-03 [ E ] me@my-pc:~$ We will be using the key displayed to configure git, here using the example key above A9E3031D40E7A31F taken from the 4 th line: sec rsa4096/A9E3031D40E7A31F 2021-06-03 [SC] Enter the following commands, substituting your name , email address , and gpg signingkey. me@my-pc:~$ git config --global gpg.program gpg me@my-pc:~$ git config --global commit.gpgsign true me@my-pc:~$ git config --global user.signingkey A9E3031D40E7A31F me@my-pc:~$ git config --global user.name \"~Your Name~\" me@my-pc:~$ git config --global user.email ~your email address~ me@my-pc:~$ Now verify that the config is correct, by typing cat ~/.gitconfig: You should see something similar to below, but with your credentials. me@my-pc:~$ cat ~/.gitconfig [ gpg ] program = gpg [ commit ] gpgsign = true [ user ] signingkey = A9E3031D40E7A31F name = ~Your Name~ email = ~your email address~ me@my-pc:~$","title":"Configuring git to use your GPG key and credentials"},{"location":"cdf/gpg-on-ubuntu/","text":"Installing GPG Using GPG, you sign tags and commits locally. These tags or commits are marked as verified on GitHub so other people in the Team can trust that the changes come from a trusted source. I suggest commit signing for all code. I really like signed code. Installation Steps Open a Ubuntu Terminal. In the terminal run the following. me@my-pc:~$ gpg --full-generate-key gpg ( GnuPG ) 2 .2.19 ; Copyright ( C ) 2019 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: ( 1 ) RSA and RSA ( default ) ( 2 ) DSA and Elgamal ( 3 ) DSA ( sign only ) ( 4 ) RSA ( sign only ) ( 14 ) Existing key from card Your selection? 1 RSA keys may be between 1024 and 4096 bits long. What keysize do you want? ( 3072 ) 4096 Requested keysize is 4096 bits Please specify how long the key should be valid. 0 = key does not expire <n> = key expires in n days <n>w = key expires in n weeks <n>m = key expires in n months <n>y = key expires in n years Key is valid for ? ( 0 ) 0 Key does not expire at all If you have made no mistakes, Type Y, press Enter/Return, otherwise type N to restart the process. Is this correct? ( y/N ) y Now, proceed with setting up your credentials for signing. In this example, I am using ~Your Name~ and ~your email address~ , for demonstration purposes. Use your own name and email. GnuPG needs to construct a user ID to identify your key. Real name: ~Your Name~ Email address: ~your email address~ Comment: enter comment here You selected this USER-ID: \"~Your Name~ (enter comment here) <~your email address~>\" Change ( N ) ame, ( C ) omment, ( E ) mail or ( O ) kay/ ( Q ) uit? If you have made no mistakes, Type O , press Enter/Return, otherwise type N , E , or C to fix the appropriate part of the key, then press O to continue. After a while, the password dialog box shown will appear, enter a good passphrase twice to protect your key, then click OK to continue. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Please enter a passphrase \u2502 \u2502 Passphrase: ***********____________________________ \u2502 \u2502 <OK> <Cancel> \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 And to confirm \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Please re-enter this passphrase \u2502 \u2502 Passphrase: ***********____________________________ \u2502 \u2502 <OK> <Cancel> \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilise the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. gpg: /home/devops/.gnupg/trustdb.gpg: trustdb created gpg: key A9E3031D40E7A31F marked as ultimately trusted gpg: directory '/home/devops/.gnupg/openpgp-revocs.d' created gpg: revocation certificate stored as '/home/devops/.gnupg/openpgp-revocs.d/71859D719307C206B6936735A9E3031D40E7A31F.rev' public and secret key created and signed. pub rsa4096 2021 -06-03 [ SC ] 71859D719307C206B6936735A9E3031D40E7A31F uid ~Your Name~ ( enter comment here ) ~your email address~ sub rsa4096 2021 -06-03 [ E ] me@my-pc:~$ The detail of your pubring.kbx should show your newly created key. List your key details as follows. me@my-pc:~$ gpg --list-secret-keys --keyid-format LONG /home/devops/.gnupg/pubring.kbx ------------------------------- sec rsa4096/A9E3031D40E7A31F 2021 -06-03 [ SC ] 71859D719307C206B6936735A9E3031D40E7A31F uid [ ultimate ] ~Your Name~ ( enter comment here ) ~your email address~ ssb rsa4096/B8239EB7C4286DAB 2021 -06-03 [ E ] me@my-pc:~$ The last thing to do is ensure that GPG knows where to execute its signing process. To configure this, run the following in your Ubuntu terminal: me@my-pc:~$ echo \"export GPG_TTY= $( tty ) \" >> ~/.bashrc me@my-pc:~$ source ~/.bashrc me@my-pc:~$ env | grep GPG GPG_TTY = /dev/pts/0 me@my-pc:~$ GPG is now installed and configured. Adding your GPG Public Key to Github In the upper-right corner of any page, click your profile photo, then click Settings. In the user settings sidebar, click SSH and GPG keys. Click New GPG key . In the same terminal that you had open for the creation of your GPG key, again, type the following to list your gpg keys. Again for demonstration purposes I am using ~Your Name~'s here. me@my-pc:~$ gpg --list-secret-keys --keyid-format LONG /home/devops/.gnupg/pubring.kbx ------------------------------- sec rsa4096/A9E3031D40E7A31F 2021 -06-03 [ SC ] 71859D719307C206B6936735A9E3031D40E7A31F uid [ ultimate ] ~Your Name~ ( enter comment here ) ~your email address~ ssb rsa4096/B8239EB7C4286DAB 2021 -06-03 [ E ] me@my-pc:~$ From the list of GPG keys, copy the GPG key ID that corresponds to your credentials. In this example, the GPG key ID is A9E3031D40E7A31F from the line beginning with sec above. Now we export the public key associated with your credential, by running the following. In the example here we are using the key listed above. This exports the key in ASCII format to allow for copying to GitHub. me@my-pc:~$ gpg --armor --export A9E3031D40E7A31F -----BEGIN PGP PUBLIC KEY BLOCK----- # Copy this line as well\u2022 mQINBF3/pfYBEADBtsYohFlwuKqFcuekU3CybI3dAY4K/kFfQQHOiSRc/n4KAXc3 WdA3NscYfLjYURfGpS2A91dV5XUkyN7J70w2q7SII4TXndpsEfXBEq0/Iv8Qj6Al hXofy4XRR2KZBRZdbxqHBrmrxpRVR6meBYOpOVxptxkq64i4nyJVLVRDMXm7isA9 RNIcRBzO5ycuSrNvsh9ZyruLWEIHcWR9maYd6nRjjhTjV8VMbwqay1KmNPQbJbxF \u2022<!-- snipped text for convenience --> \u2022LOu4rLotu1Z8MYqp4ZY89vur1E81vDMULB0I8ejYgwKBbLDqVfWgpy+z5rHTEwoK 8aJ9iLRuVPt0R97akNSyOdbSYjsU36I06KijB+uLBi4mKQ5q4Y08eIfSDSas5YlD +OLY6oPTvc3WL8U == GdYQ -----END PGP PUBLIC KEY BLOCK----- # Copy this line as well Select your key including the BEGIN/END lines, as indicated above, and paste the text into the Key field in GitHub Click the green Add GPG Key button. When prompted, confirm your GitHub password. Your GPG Key has now been added and is ready for use with GitHub.","title":"GPG on Ubuntu/GitHub"},{"location":"cdf/gpg-on-ubuntu/#installing-gpg","text":"Using GPG, you sign tags and commits locally. These tags or commits are marked as verified on GitHub so other people in the Team can trust that the changes come from a trusted source. I suggest commit signing for all code. I really like signed code.","title":"Installing GPG"},{"location":"cdf/gpg-on-ubuntu/#installation-steps","text":"Open a Ubuntu Terminal. In the terminal run the following. me@my-pc:~$ gpg --full-generate-key gpg ( GnuPG ) 2 .2.19 ; Copyright ( C ) 2019 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: ( 1 ) RSA and RSA ( default ) ( 2 ) DSA and Elgamal ( 3 ) DSA ( sign only ) ( 4 ) RSA ( sign only ) ( 14 ) Existing key from card Your selection? 1 RSA keys may be between 1024 and 4096 bits long. What keysize do you want? ( 3072 ) 4096 Requested keysize is 4096 bits Please specify how long the key should be valid. 0 = key does not expire <n> = key expires in n days <n>w = key expires in n weeks <n>m = key expires in n months <n>y = key expires in n years Key is valid for ? ( 0 ) 0 Key does not expire at all If you have made no mistakes, Type Y, press Enter/Return, otherwise type N to restart the process. Is this correct? ( y/N ) y Now, proceed with setting up your credentials for signing. In this example, I am using ~Your Name~ and ~your email address~ , for demonstration purposes. Use your own name and email. GnuPG needs to construct a user ID to identify your key. Real name: ~Your Name~ Email address: ~your email address~ Comment: enter comment here You selected this USER-ID: \"~Your Name~ (enter comment here) <~your email address~>\" Change ( N ) ame, ( C ) omment, ( E ) mail or ( O ) kay/ ( Q ) uit? If you have made no mistakes, Type O , press Enter/Return, otherwise type N , E , or C to fix the appropriate part of the key, then press O to continue. After a while, the password dialog box shown will appear, enter a good passphrase twice to protect your key, then click OK to continue. \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Please enter a passphrase \u2502 \u2502 Passphrase: ***********____________________________ \u2502 \u2502 <OK> <Cancel> \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 And to confirm \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 Please re-enter this passphrase \u2502 \u2502 Passphrase: ***********____________________________ \u2502 \u2502 <OK> <Cancel> \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilise the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. gpg: /home/devops/.gnupg/trustdb.gpg: trustdb created gpg: key A9E3031D40E7A31F marked as ultimately trusted gpg: directory '/home/devops/.gnupg/openpgp-revocs.d' created gpg: revocation certificate stored as '/home/devops/.gnupg/openpgp-revocs.d/71859D719307C206B6936735A9E3031D40E7A31F.rev' public and secret key created and signed. pub rsa4096 2021 -06-03 [ SC ] 71859D719307C206B6936735A9E3031D40E7A31F uid ~Your Name~ ( enter comment here ) ~your email address~ sub rsa4096 2021 -06-03 [ E ] me@my-pc:~$ The detail of your pubring.kbx should show your newly created key. List your key details as follows. me@my-pc:~$ gpg --list-secret-keys --keyid-format LONG /home/devops/.gnupg/pubring.kbx ------------------------------- sec rsa4096/A9E3031D40E7A31F 2021 -06-03 [ SC ] 71859D719307C206B6936735A9E3031D40E7A31F uid [ ultimate ] ~Your Name~ ( enter comment here ) ~your email address~ ssb rsa4096/B8239EB7C4286DAB 2021 -06-03 [ E ] me@my-pc:~$ The last thing to do is ensure that GPG knows where to execute its signing process. To configure this, run the following in your Ubuntu terminal: me@my-pc:~$ echo \"export GPG_TTY= $( tty ) \" >> ~/.bashrc me@my-pc:~$ source ~/.bashrc me@my-pc:~$ env | grep GPG GPG_TTY = /dev/pts/0 me@my-pc:~$ GPG is now installed and configured.","title":"Installation Steps"},{"location":"cdf/gpg-on-ubuntu/#adding-your-gpg-public-key-to-github","text":"In the upper-right corner of any page, click your profile photo, then click Settings. In the user settings sidebar, click SSH and GPG keys. Click New GPG key . In the same terminal that you had open for the creation of your GPG key, again, type the following to list your gpg keys. Again for demonstration purposes I am using ~Your Name~'s here. me@my-pc:~$ gpg --list-secret-keys --keyid-format LONG /home/devops/.gnupg/pubring.kbx ------------------------------- sec rsa4096/A9E3031D40E7A31F 2021 -06-03 [ SC ] 71859D719307C206B6936735A9E3031D40E7A31F uid [ ultimate ] ~Your Name~ ( enter comment here ) ~your email address~ ssb rsa4096/B8239EB7C4286DAB 2021 -06-03 [ E ] me@my-pc:~$ From the list of GPG keys, copy the GPG key ID that corresponds to your credentials. In this example, the GPG key ID is A9E3031D40E7A31F from the line beginning with sec above. Now we export the public key associated with your credential, by running the following. In the example here we are using the key listed above. This exports the key in ASCII format to allow for copying to GitHub. me@my-pc:~$ gpg --armor --export A9E3031D40E7A31F -----BEGIN PGP PUBLIC KEY BLOCK----- # Copy this line as well\u2022 mQINBF3/pfYBEADBtsYohFlwuKqFcuekU3CybI3dAY4K/kFfQQHOiSRc/n4KAXc3 WdA3NscYfLjYURfGpS2A91dV5XUkyN7J70w2q7SII4TXndpsEfXBEq0/Iv8Qj6Al hXofy4XRR2KZBRZdbxqHBrmrxpRVR6meBYOpOVxptxkq64i4nyJVLVRDMXm7isA9 RNIcRBzO5ycuSrNvsh9ZyruLWEIHcWR9maYd6nRjjhTjV8VMbwqay1KmNPQbJbxF \u2022<!-- snipped text for convenience --> \u2022LOu4rLotu1Z8MYqp4ZY89vur1E81vDMULB0I8ejYgwKBbLDqVfWgpy+z5rHTEwoK 8aJ9iLRuVPt0R97akNSyOdbSYjsU36I06KijB+uLBi4mKQ5q4Y08eIfSDSas5YlD +OLY6oPTvc3WL8U == GdYQ -----END PGP PUBLIC KEY BLOCK----- # Copy this line as well Select your key including the BEGIN/END lines, as indicated above, and paste the text into the Key field in GitHub Click the green Add GPG Key button. When prompted, confirm your GitHub password. Your GPG Key has now been added and is ready for use with GitHub.","title":"Adding your GPG Public Key to Github"},{"location":"cdf/prerequisites/","text":"Prerequisites Before downloading and installing the software, a couple of tasks must first be completed, to enable seamless integration with target production platforms, version control, and to allow for collaboration cross-platform projects within the DevOps team. System Requirements Windows 10 machines must meet the following requirements to install the DevOps Environment: Understanding which version you are using is not required, just ensure that you are running either: version 2004 for the consumer edition version 20H2 for the business edition Enable the WSL 2 feature on Windows, The following hardware prerequisites are required: 64 bit processor with Second Level Address Translation (SLAT) 8GB system RAM BIOS-level hardware virtualization support must be enabled in the BIOS settings. Download and install the Linux kernel update package. Checking your Windows Version Check your Windows version by selecting the Windows logo key + R , type winver, select OK . (Or enter the ver command in Windows Command Prompt) Consumer Edition Business Edition If your version is NOT 2004/20H2, please update to the latest Windows via Windows Update, as follows. Click the Windows Logo then settings: Then select Update & Security , and Windows Update . Apply any outstanding updates that you have rebooting when asked. Eventually you will open the Windows Update panel and see: If you have a consumer edition of Windows If you have the business edition of Windows Click, Download and install . The Windows Update page will change to something similar to below showing that Windows 10, Version 2004 is installing. Go take a nap at this point (the process to just over an hour and 40 minutes for me), as the update process will rotate thru several status changes, Getting things ready , Downloading , and Installing . Consumer Edition Business Edition After your nap, check and you will see that the update has completed, and that Your system can be rebooted. Press the Restart now button, and restart. Install the Windows Subsystem for Linux Now we need to enable the \"Windows Subsystem for Linux\" optional feature, which is used by Docker to host the containers used by VS Code. Open PowerShell as Administrator and run: PS C :\\ WINDOWS \\ system32 \\> dism . exe / online / enable-feature / featurename : Microsoft-Windows-Subsystem-Linux / all / norestart Deployment Image Servicing and Management tool Version : 10 . 0 . 19041 . 329 Image Version : 10 . 0 . 19041 . 329 Enabling feature ( s ) [========================== 100 . 0 %==========================] The operation completed successfully . Update to WSL 2 Enable the 'Virtual Machine Platform' optional component Before installing WSL 2, you must enable the \"Virtual Machine Platform\" optional feature. Open PowerShell as Administrator and run: PS C :\\ WINDOWS \\ system32 \\> dism . exe / online / enable-feature / featurename : VirtualMachinePlatform / all / norestart Deployment Image Servicing and Management tool Version : 10 . 0 . 19041 . 329 Image Version : 10 . 0 . 19041 . 329 Enabling feature ( s ) [========================== 100 . 0 %==========================] The operation completed successfully . Restart your machine to complete the WSL install and update to WSL 2. PS C :\\ WINDOWS \\ system32 \\> restart-computer Set WSL 2 as your default version Run the following command in PowerShell as Administrator to set WSL 2 as the default version: PS C :\\ WINDOWS \\ system32 \\> wsl - -set-default-version 2 You might see this message after running that command: WSL 2 requires an update to its kernel component Please click this link and run the downloaded MSI to install the Linux kernel on your machine for WSL 2 to use. Once you have the kernel installed, please run the following command again and it should complete successfully without showing the warning message about the kernel component. wsl - -set-default-version 2","title":"Prerequisites"},{"location":"cdf/prerequisites/#prerequisites","text":"Before downloading and installing the software, a couple of tasks must first be completed, to enable seamless integration with target production platforms, version control, and to allow for collaboration cross-platform projects within the DevOps team.","title":"Prerequisites"},{"location":"cdf/prerequisites/#system-requirements","text":"Windows 10 machines must meet the following requirements to install the DevOps Environment: Understanding which version you are using is not required, just ensure that you are running either: version 2004 for the consumer edition version 20H2 for the business edition Enable the WSL 2 feature on Windows, The following hardware prerequisites are required: 64 bit processor with Second Level Address Translation (SLAT) 8GB system RAM BIOS-level hardware virtualization support must be enabled in the BIOS settings. Download and install the Linux kernel update package.","title":"System Requirements"},{"location":"cdf/prerequisites/#checking-your-windows-version","text":"Check your Windows version by selecting the Windows logo key + R , type winver, select OK . (Or enter the ver command in Windows Command Prompt) Consumer Edition Business Edition If your version is NOT 2004/20H2, please update to the latest Windows via Windows Update, as follows. Click the Windows Logo then settings: Then select Update & Security , and Windows Update . Apply any outstanding updates that you have rebooting when asked. Eventually you will open the Windows Update panel and see: If you have a consumer edition of Windows If you have the business edition of Windows Click, Download and install . The Windows Update page will change to something similar to below showing that Windows 10, Version 2004 is installing. Go take a nap at this point (the process to just over an hour and 40 minutes for me), as the update process will rotate thru several status changes, Getting things ready , Downloading , and Installing . Consumer Edition Business Edition After your nap, check and you will see that the update has completed, and that Your system can be rebooted. Press the Restart now button, and restart.","title":"Checking your Windows Version"},{"location":"cdf/prerequisites/#install-the-windows-subsystem-for-linux","text":"Now we need to enable the \"Windows Subsystem for Linux\" optional feature, which is used by Docker to host the containers used by VS Code. Open PowerShell as Administrator and run: PS C :\\ WINDOWS \\ system32 \\> dism . exe / online / enable-feature / featurename : Microsoft-Windows-Subsystem-Linux / all / norestart Deployment Image Servicing and Management tool Version : 10 . 0 . 19041 . 329 Image Version : 10 . 0 . 19041 . 329 Enabling feature ( s ) [========================== 100 . 0 %==========================] The operation completed successfully .","title":"Install the Windows Subsystem for Linux"},{"location":"cdf/prerequisites/#update-to-wsl-2","text":"Enable the 'Virtual Machine Platform' optional component Before installing WSL 2, you must enable the \"Virtual Machine Platform\" optional feature. Open PowerShell as Administrator and run: PS C :\\ WINDOWS \\ system32 \\> dism . exe / online / enable-feature / featurename : VirtualMachinePlatform / all / norestart Deployment Image Servicing and Management tool Version : 10 . 0 . 19041 . 329 Image Version : 10 . 0 . 19041 . 329 Enabling feature ( s ) [========================== 100 . 0 %==========================] The operation completed successfully . Restart your machine to complete the WSL install and update to WSL 2. PS C :\\ WINDOWS \\ system32 \\> restart-computer","title":"Update to WSL 2"},{"location":"cdf/prerequisites/#set-wsl-2-as-your-default-version","text":"Run the following command in PowerShell as Administrator to set WSL 2 as the default version: PS C :\\ WINDOWS \\ system32 \\> wsl - -set-default-version 2 You might see this message after running that command: WSL 2 requires an update to its kernel component Please click this link and run the downloaded MSI to install the Linux kernel on your machine for WSL 2 to use. Once you have the kernel installed, please run the following command again and it should complete successfully without showing the warning message about the kernel component. wsl - -set-default-version 2","title":"Set WSL 2 as your default version"},{"location":"cdf/ssh-on-ubuntu/","text":"Configure SSH to authenticate on Ubuntu Using the SSH protocol, you can connect and authenticate to remote servers and services. With SSH keys, you can connect to GitHub without supplying your username or password at each visit. This section will show you how to configure SSH on Linux, and add your Key to your GitHub Account. Click, Start and open a Ubuntu terminal window, and paste the text below, substituting in your Email Address. This creates a new ssh key, using the provided email as a label. When you're prompted to Enter a file in which to save the key, press Enter. This accepts the default file location. me@my-pc:~ $ ssh-keygen -t rsa -b 4096 -C \"~your email address~\" Enter a file in which to save the key ( /home/you/.ssh/id_rsa ) : [ Press enter ] At the password prompt, press enter, or type a secure passphrase, if you use an ssh-agent. > Enter passphrase ( empty for no passphrase ) : [ Press enter ] > Enter same passphrase again: [ Press enter ] Your identification has been saved in id-rsa. Your public key has been saved in id-rsa.pub. The key fingerprint is: SHA256:< A long string of what looks like gibberish > ~your email address~ The key 's randomart image is: +---[RSA 4096]----+ | . =*B +| A nice lil' graphic | . = *B + | +---- [ SHA256 ] -----+ me@my-pc:~ $ Configuring GitHub to use SSH Log into GitHub. In the upper-right corner of any page, click your profile photo, then click Settings. In the user settings sidebar, click SSH and GPG keys. Then Click New SSH key or Add SSH key . In the Title field, add a descriptive label for the new key. For example, if you're using the a Dell Laptop, you might call this key My Dell . To copy the SSH public key for addition to GitHub run the following on your OS In the Ubuntu Terminal on Windows, and at the prompt type the following: cat ~/.ssh/id_rsa.pub Copy the resultant output in its entirety, including email address. Do NOT add line-breaks manually. me@my-pc:~$ cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCmwEDEM2rqfqoy25rNJzXfHYcHb1 wHSVUoWRfK6aYfQGYpWyRLBFE5t9DkJiMH5dV+dx6qkCAJhFFu+r2RMVJD gmkfjAw8I/2U+PPMApJ8RfH+lrVaz2fYkmEetgwWM0UNEJ5IPmMauZahPE ljlJoKyXTa25Z2KFEJVljd4jnFHr2iuyMgIql3Dt26jZkebgEytaWQTJ9Z W3NoPXqBd0+kYPyQc8NXj2gTwKwaEFgWAdIu3WPUM/utrtSHp12ePD6UgH H6siE9xXJUSCgZgZcAVAF2ZTd5y1fa07SvgM8tsV7JavDp62TLw+xpYQhr htWYpHkIGCaKQHZGKedYnRkjZB9/d0BYflpvLWnjtFanfj3g1RgnNBw2p8 zSl9PwLaQQNsVtGcg60D97TanZIzSD+yWPliZrrIAH8ncOExoGk8s85dWj pcvxyrKX52kbG5tk51niE/MgQxlRwse9BLFLVlc50BCHn1i27+TJuFHiO+ 16uXU1PyN88ZXAT2xgb2uIsxCb4CNBM0L6scwLRj+uLCHCghhdF6zoUvT1 8qtyZsvDu86e0x53ez8zCoX4K/6zYSZQOz+mkSa6DWqCIeeua0EQA/Cw1i gaCj5X7kKiytLpRT2C1rIb+NP1SEZTyuju+0v2H/kBJPjf6PJJXpByoTU6 gyZfbYLwJrLBAx8PqQ == ~your email address~ Paste your key into the _ Key** field. Click Add SSH key . When prompted, confirm your GitHub password. Your SSH Key has now been added and is ready for use with GitHub","title":"SSH on Ubuntu/GitHub"},{"location":"cdf/ssh-on-ubuntu/#configure-ssh-to-authenticate-on-ubuntu","text":"Using the SSH protocol, you can connect and authenticate to remote servers and services. With SSH keys, you can connect to GitHub without supplying your username or password at each visit. This section will show you how to configure SSH on Linux, and add your Key to your GitHub Account. Click, Start and open a Ubuntu terminal window, and paste the text below, substituting in your Email Address. This creates a new ssh key, using the provided email as a label. When you're prompted to Enter a file in which to save the key, press Enter. This accepts the default file location. me@my-pc:~ $ ssh-keygen -t rsa -b 4096 -C \"~your email address~\" Enter a file in which to save the key ( /home/you/.ssh/id_rsa ) : [ Press enter ] At the password prompt, press enter, or type a secure passphrase, if you use an ssh-agent. > Enter passphrase ( empty for no passphrase ) : [ Press enter ] > Enter same passphrase again: [ Press enter ] Your identification has been saved in id-rsa. Your public key has been saved in id-rsa.pub. The key fingerprint is: SHA256:< A long string of what looks like gibberish > ~your email address~ The key 's randomart image is: +---[RSA 4096]----+ | . =*B +| A nice lil' graphic | . = *B + | +---- [ SHA256 ] -----+ me@my-pc:~ $","title":"Configure SSH to authenticate on Ubuntu"},{"location":"cdf/ssh-on-ubuntu/#configuring-github-to-use-ssh","text":"Log into GitHub. In the upper-right corner of any page, click your profile photo, then click Settings. In the user settings sidebar, click SSH and GPG keys. Then Click New SSH key or Add SSH key . In the Title field, add a descriptive label for the new key. For example, if you're using the a Dell Laptop, you might call this key My Dell . To copy the SSH public key for addition to GitHub run the following on your OS In the Ubuntu Terminal on Windows, and at the prompt type the following: cat ~/.ssh/id_rsa.pub Copy the resultant output in its entirety, including email address. Do NOT add line-breaks manually. me@my-pc:~$ cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQCmwEDEM2rqfqoy25rNJzXfHYcHb1 wHSVUoWRfK6aYfQGYpWyRLBFE5t9DkJiMH5dV+dx6qkCAJhFFu+r2RMVJD gmkfjAw8I/2U+PPMApJ8RfH+lrVaz2fYkmEetgwWM0UNEJ5IPmMauZahPE ljlJoKyXTa25Z2KFEJVljd4jnFHr2iuyMgIql3Dt26jZkebgEytaWQTJ9Z W3NoPXqBd0+kYPyQc8NXj2gTwKwaEFgWAdIu3WPUM/utrtSHp12ePD6UgH H6siE9xXJUSCgZgZcAVAF2ZTd5y1fa07SvgM8tsV7JavDp62TLw+xpYQhr htWYpHkIGCaKQHZGKedYnRkjZB9/d0BYflpvLWnjtFanfj3g1RgnNBw2p8 zSl9PwLaQQNsVtGcg60D97TanZIzSD+yWPliZrrIAH8ncOExoGk8s85dWj pcvxyrKX52kbG5tk51niE/MgQxlRwse9BLFLVlc50BCHn1i27+TJuFHiO+ 16uXU1PyN88ZXAT2xgb2uIsxCb4CNBM0L6scwLRj+uLCHCghhdF6zoUvT1 8qtyZsvDu86e0x53ez8zCoX4K/6zYSZQOz+mkSa6DWqCIeeua0EQA/Cw1i gaCj5X7kKiytLpRT2C1rIb+NP1SEZTyuju+0v2H/kBJPjf6PJJXpByoTU6 gyZfbYLwJrLBAx8PqQ == ~your email address~ Paste your key into the _ Key** field. Click Add SSH key . When prompted, confirm your GitHub password. Your SSH Key has now been added and is ready for use with GitHub","title":"Configuring GitHub to use SSH"},{"location":"cdf/ubuntu/","text":"Install the Ubuntu Linux distribution from Microsoft Store If you already have Ubuntu installed you can skip to Set your distribution version to WSL 2 . Open the Microsoft Store and search for Ubuntu 20.04. (CentOS is available, but it is not free AND is managed by a team in China, NOT the CentOS group). Ubuntu is managed by Canonical. Once chosen, click on get and install. If asked to enter your Microsoft ID, you can say 'No, thanks', Ubuntu will start downloading. Once downloaded, click Launch , a new window will open. Configuring Ubuntu when first used When first launched Ubuntu will start some configuration. Ubuntu is now running some initial startup programs to prepare the Ubuntu environment for use. When prompted, enter a username (it is recommended for simplicity that current user ID be used. in this example, 'pmclean' is used) Ubuntu is now configured and ready for use! Configuring package repositories To be able to maintain and allow for future enhancements, the Ubuntu installation needs to be configured for updates, and then brought up to date. The first step in preparing update, is to refresh the package repositories in the Ubuntu instance. To update the software repositories, at the command prompt sudo apt-get update Enter the sudo password . This will be the password that was entered for the account on first run, and will be used going forward to execute ALL sudo command. Ubuntu will now update the local repository cache with the latest build information Now, upgrade Ubuntu to use the latest version of all installed packages. sudo apt-get -y upgrade In this example, all packages were up to date, so no packages were updated Type exit and then enter/return to close the window. Set your distribution version to WSL 2 You can check the WSL version assigned to each of the Linux distributions you have installed by opening the PowerShell command line and entering the command (only available in Windows Build 19041 or higher): wsl -l -v If you are running the un-numbered version of Ubuntu you will see PS C :\\ Users \\ me \\> wsl -l -v NAME STATE VERSION Ubuntu Running 2 PS C :\\ Users \\ me \\> For Ubuntu 18.04 PS C :\\ Users \\ me \\> wsl -l -v NAME STATE VERSION Ubuntu - 18 . 04 Running 2 PS C :\\ Users \\ me \\> For Ubuntu 20.04 PS C :\\ Users \\ me \\> wsl -l -v NAME STATE VERSION Ubuntu - 20 . 04 Running 2 PS C :\\ Users \\ me \\> If your Version shows up as 1 , set the distribution to be backed by WSL2 , so please run: PS C :\\ Users \\ me \\> wsl - -set-version Ubuntu 2 # If you have the Ubuntu un-numbered PS C :\\ Users \\ me \\> wsl - -set-version Ubuntu - 18 . 04 2 # If you have the Ubuntu 18.04 PS C :\\ Users \\ me \\> wsl - -set-version Ubuntu - 20 . 04 2 # If you have the Ubuntu 20.04 Conversion in progress , this may take a few minutes ... For information on key differences with WSL 2 please visit https :// aka . ms / wsl2 Conversion complete . PS C :\\ Users \\ me \\> wsl -l -v NAME STATE VERSION Ubuntu - 20 . 04 Running 2 PS C :\\ Users \\ me \\>","title":"Install Ubuntu on Windows"},{"location":"cdf/ubuntu/#install-the-ubuntu-linux-distribution-from-microsoft-store","text":"If you already have Ubuntu installed you can skip to Set your distribution version to WSL 2 . Open the Microsoft Store and search for Ubuntu 20.04. (CentOS is available, but it is not free AND is managed by a team in China, NOT the CentOS group). Ubuntu is managed by Canonical. Once chosen, click on get and install. If asked to enter your Microsoft ID, you can say 'No, thanks', Ubuntu will start downloading. Once downloaded, click Launch , a new window will open.","title":"Install the Ubuntu Linux distribution from Microsoft Store"},{"location":"cdf/ubuntu/#configuring-ubuntu-when-first-used","text":"When first launched Ubuntu will start some configuration. Ubuntu is now running some initial startup programs to prepare the Ubuntu environment for use. When prompted, enter a username (it is recommended for simplicity that current user ID be used. in this example, 'pmclean' is used) Ubuntu is now configured and ready for use!","title":"Configuring Ubuntu when first used"},{"location":"cdf/ubuntu/#configuring-package-repositories","text":"To be able to maintain and allow for future enhancements, the Ubuntu installation needs to be configured for updates, and then brought up to date. The first step in preparing update, is to refresh the package repositories in the Ubuntu instance. To update the software repositories, at the command prompt sudo apt-get update Enter the sudo password . This will be the password that was entered for the account on first run, and will be used going forward to execute ALL sudo command. Ubuntu will now update the local repository cache with the latest build information Now, upgrade Ubuntu to use the latest version of all installed packages. sudo apt-get -y upgrade In this example, all packages were up to date, so no packages were updated Type exit and then enter/return to close the window.","title":"Configuring package repositories"},{"location":"cdf/ubuntu/#set-your-distribution-version-to-wsl-2","text":"You can check the WSL version assigned to each of the Linux distributions you have installed by opening the PowerShell command line and entering the command (only available in Windows Build 19041 or higher): wsl -l -v If you are running the un-numbered version of Ubuntu you will see PS C :\\ Users \\ me \\> wsl -l -v NAME STATE VERSION Ubuntu Running 2 PS C :\\ Users \\ me \\> For Ubuntu 18.04 PS C :\\ Users \\ me \\> wsl -l -v NAME STATE VERSION Ubuntu - 18 . 04 Running 2 PS C :\\ Users \\ me \\> For Ubuntu 20.04 PS C :\\ Users \\ me \\> wsl -l -v NAME STATE VERSION Ubuntu - 20 . 04 Running 2 PS C :\\ Users \\ me \\> If your Version shows up as 1 , set the distribution to be backed by WSL2 , so please run: PS C :\\ Users \\ me \\> wsl - -set-version Ubuntu 2 # If you have the Ubuntu un-numbered PS C :\\ Users \\ me \\> wsl - -set-version Ubuntu - 18 . 04 2 # If you have the Ubuntu 18.04 PS C :\\ Users \\ me \\> wsl - -set-version Ubuntu - 20 . 04 2 # If you have the Ubuntu 20.04 Conversion in progress , this may take a few minutes ... For information on key differences with WSL 2 please visit https :// aka . ms / wsl2 Conversion complete . PS C :\\ Users \\ me \\> wsl -l -v NAME STATE VERSION Ubuntu - 20 . 04 Running 2 PS C :\\ Users \\ me \\>","title":"Set your distribution version to WSL 2"},{"location":"cdf/vscode/","text":"Visual Studio Code is a lightweight but powerful source code editor which runs on your desktop and is available for Windows, macOS and Linux. It comes with built-in support for JavaScript, TypeScript and Node.js and has a rich ecosystem of extensions for other languages (such as C++, C#, Java, Python, PHP, Go) and runtimes (such as .NET and Unity). It also integrates seamlessly with Docker to allow for developing inside Docker containers. \"So what, Pat?\" I hear you say? Well, how about having your entire development environment and source all stored as code. This gives a consistent development environment for an entire team. All developers use the same OS for development, the same system libraries, and the same language runtime, no matter what host OS they are using. Installation Download the System Installer for windows from the Visual Studio Code Download page Accept the licence agreement, and click Next until you get to the Select Additional Task window. Ensure that the bottom 4 check boxes are ticked , then click Next . Installation will start, and complete. Launch Visual Studio Code. Installing the Docker Development Extensions With Visual Studio Code open, click on the '4-cube' icon to open the extensions sidebar. Type remote into the search box at the top, then click Remote - Container . Ensure that the extension is the 'Remote-Containers' Extension as owned by Microsoft, seen from the screenshot. Click the Green Install Button. Type docker into the search box at the top, then click Docker . Ensure that the extension is the 'Docker' Extension as owned by Microsoft, seen from the screenshot. Click the Green Install Button. Visual Studio Code is now configured, and can now be closed.","title":"Visual Studio Code"},{"location":"cdf/vscode/#installation","text":"Download the System Installer for windows from the Visual Studio Code Download page Accept the licence agreement, and click Next until you get to the Select Additional Task window. Ensure that the bottom 4 check boxes are ticked , then click Next . Installation will start, and complete. Launch Visual Studio Code.","title":"Installation"},{"location":"cdf/vscode/#installing-the-docker-development-extensions","text":"With Visual Studio Code open, click on the '4-cube' icon to open the extensions sidebar. Type remote into the search box at the top, then click Remote - Container . Ensure that the extension is the 'Remote-Containers' Extension as owned by Microsoft, seen from the screenshot. Click the Green Install Button. Type docker into the search box at the top, then click Docker . Ensure that the extension is the 'Docker' Extension as owned by Microsoft, seen from the screenshot. Click the Green Install Button. Visual Studio Code is now configured, and can now be closed.","title":"Installing the Docker Development Extensions"},{"location":"glossary/gitflow/","text":"Development Workflow using Git and GitHub Main branches At the core, the development model is greatly inspired by existing models out there. The central repo holds two main branches with an infinite lifetime: The master branch at origin should be familiar to every Git user. Parallel to the master branch, another branch exists called develop . We consider origin/master to be the main branch where the source code of HEAD always reflects a production-ready state . A develop branch is created from master . We consider origin/develop to be the main branch where the source code of HEAD always reflects a state with the latest delivered development changes for the next release. Some would call this the integration branch . This is where any automatic nightly builds are built from. Feature branches Feature branches will be used to develop new features for upcoming or a distant future release. When starting development of a feature , the target release in which this feature will be incorporated may well be unknown at that point. The essence of a feature branch is that it exists as long as the feature is in development, but will eventually be merged back into develop (to definitely add the new feature to the upcoming release) or discarded (in case of a disappointing experiment). Must branch off from: develop Must merge back into: develop Branch naming convention: feature/xxx Creating a feature branch When starting work on a new feature, branch off from the develop branch. $ git checkout -b feature/xxx develop Switched to a new branch \"feature/xxx\" Merging feature branches into develop The --no-ff flag must be used in the PR to always create a new commit object, even if the merge could be performed with a fast-forward. This avoids losing information about the historical existence of a feature branch and groups together all commits that together added the feature. Once a feature has been merged into the development branch, other feature branches should merge develop into their respective feature branch. Release branches Release branches support preparation of a new production release. They allow for last-minute dotting of i\u2019s and crossing t\u2019s. Furthermore, they allow for minor bug fixes and preparing meta-data for a release (version number, build dates, etc.). By doing all of this work on a release branch, the develop branch is cleared to receive features for the next big release. Must branch off from: develop Must merge back into: develop and master / develop then is merging into any in-progress releases. Branch naming convention: release/ The key moment to branch off a new release branch from develop is when develop (almost) reflects the desired state of the new release . At least all features that are targeted for the release-to-be-built must be merged into develop at this point in time. All features targeted at future releases may not\u2014they must wait until after the release branch is branched off. It is exactly at the start of a release branch that the upcoming release gets assigned a version number\u2014not any earlier. Up until that moment, the develop branch reflected changes for the \u201cnext release\u201d, but it is unclear whether that \u201cnext release\u201d will eventually become 0.3 or 1.0, until the release branch is started. That decision is made on the start of the release branch and is carried out by the project\u2019s rules on version number bumping. This new branch may exist there for a while, until the release may be rolled out definitely. During that time, bug fixes are applied in this branch, which are then merged into the develop branch. Adding large new features here is strictly prohibited , these must be merged into develop, and therefore, wait for the next big release. When the state of the release branch is ready to become a real release, some actions need to be carried out. First, the release branch is merged into master (since every commit on master is a new release by definition, remember). Next, that commit on master must be tagged for easy future reference to this historical version. Finally, the changes made on the release branch need to be merged back into develop, so that future releases also contain these bug fixes. HotFix branches Hotfix branches are very much like release branches in that they are also meant to prepare for a new production release, albeit unplanned. They arise from the necessity to act immediately upon any undesired state of a live production version. When a critical bug in a production version must be resolved immediately, a hotfix branch should be branched off from the corresponding tag on the master branch that marks the production version. May branch off from: master Must merge back into: develop and master Branch naming convention: hotfix/xxx The allows team members to continue to work on the develop branch, while another person is preparing a quick production fix. When finished, the bugfix needs to be merged back into master , but also needs to be merged back into develop , in order to safeguard that the bugfix is included in the next release as well. This is completely similar to how release branches are finished. Summary The complete process described above as a single diagram.","title":"Using GitFlow"},{"location":"glossary/gitflow/#development-workflow-using-git-and-github","text":"","title":"Development Workflow using Git and GitHub"},{"location":"glossary/gitflow/#main-branches","text":"At the core, the development model is greatly inspired by existing models out there. The central repo holds two main branches with an infinite lifetime: The master branch at origin should be familiar to every Git user. Parallel to the master branch, another branch exists called develop . We consider origin/master to be the main branch where the source code of HEAD always reflects a production-ready state . A develop branch is created from master . We consider origin/develop to be the main branch where the source code of HEAD always reflects a state with the latest delivered development changes for the next release. Some would call this the integration branch . This is where any automatic nightly builds are built from.","title":"Main branches"},{"location":"glossary/gitflow/#feature-branches","text":"Feature branches will be used to develop new features for upcoming or a distant future release. When starting development of a feature , the target release in which this feature will be incorporated may well be unknown at that point. The essence of a feature branch is that it exists as long as the feature is in development, but will eventually be merged back into develop (to definitely add the new feature to the upcoming release) or discarded (in case of a disappointing experiment). Must branch off from: develop Must merge back into: develop Branch naming convention: feature/xxx","title":"Feature branches"},{"location":"glossary/gitflow/#creating-a-feature-branch","text":"When starting work on a new feature, branch off from the develop branch. $ git checkout -b feature/xxx develop Switched to a new branch \"feature/xxx\"","title":"Creating a feature branch"},{"location":"glossary/gitflow/#merging-feature-branches-into-develop","text":"The --no-ff flag must be used in the PR to always create a new commit object, even if the merge could be performed with a fast-forward. This avoids losing information about the historical existence of a feature branch and groups together all commits that together added the feature. Once a feature has been merged into the development branch, other feature branches should merge develop into their respective feature branch.","title":"Merging feature branches into develop"},{"location":"glossary/gitflow/#release-branches","text":"Release branches support preparation of a new production release. They allow for last-minute dotting of i\u2019s and crossing t\u2019s. Furthermore, they allow for minor bug fixes and preparing meta-data for a release (version number, build dates, etc.). By doing all of this work on a release branch, the develop branch is cleared to receive features for the next big release. Must branch off from: develop Must merge back into: develop and master / develop then is merging into any in-progress releases. Branch naming convention: release/ The key moment to branch off a new release branch from develop is when develop (almost) reflects the desired state of the new release . At least all features that are targeted for the release-to-be-built must be merged into develop at this point in time. All features targeted at future releases may not\u2014they must wait until after the release branch is branched off. It is exactly at the start of a release branch that the upcoming release gets assigned a version number\u2014not any earlier. Up until that moment, the develop branch reflected changes for the \u201cnext release\u201d, but it is unclear whether that \u201cnext release\u201d will eventually become 0.3 or 1.0, until the release branch is started. That decision is made on the start of the release branch and is carried out by the project\u2019s rules on version number bumping. This new branch may exist there for a while, until the release may be rolled out definitely. During that time, bug fixes are applied in this branch, which are then merged into the develop branch. Adding large new features here is strictly prohibited , these must be merged into develop, and therefore, wait for the next big release. When the state of the release branch is ready to become a real release, some actions need to be carried out. First, the release branch is merged into master (since every commit on master is a new release by definition, remember). Next, that commit on master must be tagged for easy future reference to this historical version. Finally, the changes made on the release branch need to be merged back into develop, so that future releases also contain these bug fixes.","title":"Release branches"},{"location":"glossary/gitflow/#hotfix-branches","text":"Hotfix branches are very much like release branches in that they are also meant to prepare for a new production release, albeit unplanned. They arise from the necessity to act immediately upon any undesired state of a live production version. When a critical bug in a production version must be resolved immediately, a hotfix branch should be branched off from the corresponding tag on the master branch that marks the production version. May branch off from: master Must merge back into: develop and master Branch naming convention: hotfix/xxx The allows team members to continue to work on the develop branch, while another person is preparing a quick production fix. When finished, the bugfix needs to be merged back into master , but also needs to be merged back into develop , in order to safeguard that the bugfix is included in the next release as well. This is completely similar to how release branches are finished.","title":"HotFix branches"},{"location":"glossary/gitflow/#summary","text":"The complete process described above as a single diagram.","title":"Summary"},{"location":"glossary/mark-down/","text":"Headers # Heading 1 ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6 Callouts !!! attention Any number of other indented markdown elements. !!! caution Any number of other indented markdown elements. !!! danger Any number of other indented markdown elements. !!! error Any number of other indented markdown elements. !!! hint Any number of other indented markdown elements. !!! important Any number of other indented markdown elements. !!! info Any number of other indented markdown elements. !!! note Any number of other indented markdown elements. !!! tip Any number of other indented markdown elements. ... becomes ... Attention Any number of other indented markdown elements. Caution Any number of other indented markdown elements. Danger Any number of other indented markdown elements. Error Any number of other indented markdown elements. Hint Any number of other indented markdown elements. Important Any number of other indented markdown elements. Info Any number of other indented markdown elements. Note Any number of other indented markdown elements. Tip Any number of other indented markdown elements. Emphasis Emphasis, aka italics, with single *asterisks* or _underscores_ . Strong emphasis, aka bold, with double **asterisks** or __underscores__ . Combined emphasis with **asterisks and _underscores_** . Strike-through uses two tildes. ~~Scratch this.~~ ... becomes ... Emphasis, aka italics, with asterisks or underscores . Strong emphasis, aka bold, with asterisks or underscores . Combined emphasis with asterisks and underscores . Strike-through uses two tildes. Scratch this. Lists (In this example, leading and trailing spaces are shown with with dots: \u22c5) 1. First ordered list item 2. Another item ....* Unordered sub-list. 1. Actual numbers don't matter, just that it's a number ....1. Ordered sub-list 4. And another item. I am a paragraph * Unordered list can use asterisks - Or minuses + Or pluses ... becomes ... First ordered list item Another item Unordered sub-list. Actual numbers don't matter, just that it's a number Ordered sub-list And another item. I am a paragraph Unordered list can use asterisks Or minuses Or pluses Links There are two ways to create links. [ I'm an inline-style link ]( https://www.google.com ) [ I'm an inline-style link with title ]( https://www.google.com \"Google's Homepage\" ) [ I'm a relative reference to a repository file ]( ../blob/master/LICENSE ) [ You can use numbers for reference-style link definitions ][ 1 ] Or leave it empty and use the [link text itself]. [ 1 ]: http://slashdot.org [ link text itself ]: http://www.reddit.com ... becomes ... I'm an inline-style link I'm an inline-style link with title I'm a relative reference to a repository file You can use numbers for reference-style link definitions Or leave it empty and use the link text itself . Images ![ alt text ]( ../cdf/img/consumer.png \"Descriptive Text\" ){{: style=\"height:48px;width:48px;align:center;\"} ... becomes ... Here's our image (hover to see the title text): Tables Tables aren't part of the core Markdown spec, but they are part of GFM and Markdown Here supports them. They are an easy way of adding tables to your email -- a task that would otherwise require copy-pasting from another application. Colons can be used to align columns. | Tables | Are | Cool | | ------------- |:-------------:| -----:| | col 3 is | right-aligned | $1600 | | col 2 is | centered | $12 | | zebra stripes | are neat | $1 | There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown | Less | Pretty --- | --- | --- *Still* | `renders` | **nicely** 1 | 2 | 3 ... becomes ... Colons can be used to align columns. Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 There must be at least 3 dashes separating each header cell. The outer pipes ( | ) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown Less Pretty Still renders nicely 1 2 3 Blockquotes > Blockquotes are very handy in email to emulate reply text. > This line is part of the same quote. Quote break. > This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can *put* **Markdown** into a blockquote. becomes: Blockquotes are very handy in email to emulate reply text. This line is part of the same quote. Quote break. This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can put Markdown into a blockquote. Inline HTML You can also use raw HTML in your Markdown, and it'll mostly work pretty well. <dl> <dt>Definition list</dt> <dd>Is something people use sometimes.</dd> <dt>Markdown in HTML</dt> <dd>Does *not* work **very** well. Use HTML <em>tags</em>.</dd> </dl> Definition list Is something people use sometimes. Markdown in HTML Does *not* work **very** well. Use HTML tags . Horizontal Rule Three or more... --- Hyphens ... becomes ... Hyphens Line Breaks My basic recommendation for learning how line breaks work is to experiment and discover -- hit <Enter> once (i.e., insert one newline), then hit it twice (i.e., insert two newlines), see what happens. You'll soon learn to get what you want. \"Markdown Toggle\" is your friend. Here are some things to try out: Here's a line for us to start with. This line is separated from the one above by two newlines, so it will be a *separate paragraph* . This line is also a separate paragraph, but... This line is only separated by a single newline, so it's a separate line in the *same paragraph* . Here's a line for us to start with. This line is separated from the one above by two newlines, so it will be a separate paragraph . This line is also begins a separate paragraph, but... This line is only separated by a single newline, so it's a separate line in the same paragraph .","title":"Markdown Cheat-sheet"},{"location":"glossary/mark-down/#headers","text":"# Heading 1 ## Heading 2 ### Heading 3 #### Heading 4 ##### Heading 5 ###### Heading 6","title":"Headers"},{"location":"glossary/mark-down/#callouts","text":"!!! attention Any number of other indented markdown elements. !!! caution Any number of other indented markdown elements. !!! danger Any number of other indented markdown elements. !!! error Any number of other indented markdown elements. !!! hint Any number of other indented markdown elements. !!! important Any number of other indented markdown elements. !!! info Any number of other indented markdown elements. !!! note Any number of other indented markdown elements. !!! tip Any number of other indented markdown elements. ... becomes ... Attention Any number of other indented markdown elements. Caution Any number of other indented markdown elements. Danger Any number of other indented markdown elements. Error Any number of other indented markdown elements. Hint Any number of other indented markdown elements. Important Any number of other indented markdown elements. Info Any number of other indented markdown elements. Note Any number of other indented markdown elements. Tip Any number of other indented markdown elements.","title":"Callouts"},{"location":"glossary/mark-down/#emphasis","text":"Emphasis, aka italics, with single *asterisks* or _underscores_ . Strong emphasis, aka bold, with double **asterisks** or __underscores__ . Combined emphasis with **asterisks and _underscores_** . Strike-through uses two tildes. ~~Scratch this.~~ ... becomes ... Emphasis, aka italics, with asterisks or underscores . Strong emphasis, aka bold, with asterisks or underscores . Combined emphasis with asterisks and underscores . Strike-through uses two tildes. Scratch this.","title":"Emphasis"},{"location":"glossary/mark-down/#lists","text":"(In this example, leading and trailing spaces are shown with with dots: \u22c5) 1. First ordered list item 2. Another item ....* Unordered sub-list. 1. Actual numbers don't matter, just that it's a number ....1. Ordered sub-list 4. And another item. I am a paragraph * Unordered list can use asterisks - Or minuses + Or pluses ... becomes ... First ordered list item Another item Unordered sub-list. Actual numbers don't matter, just that it's a number Ordered sub-list And another item. I am a paragraph Unordered list can use asterisks Or minuses Or pluses","title":"Lists"},{"location":"glossary/mark-down/#links","text":"There are two ways to create links. [ I'm an inline-style link ]( https://www.google.com ) [ I'm an inline-style link with title ]( https://www.google.com \"Google's Homepage\" ) [ I'm a relative reference to a repository file ]( ../blob/master/LICENSE ) [ You can use numbers for reference-style link definitions ][ 1 ] Or leave it empty and use the [link text itself]. [ 1 ]: http://slashdot.org [ link text itself ]: http://www.reddit.com ... becomes ... I'm an inline-style link I'm an inline-style link with title I'm a relative reference to a repository file You can use numbers for reference-style link definitions Or leave it empty and use the link text itself .","title":"Links"},{"location":"glossary/mark-down/#images","text":"![ alt text ]( ../cdf/img/consumer.png \"Descriptive Text\" ){{: style=\"height:48px;width:48px;align:center;\"} ... becomes ... Here's our image (hover to see the title text):","title":"Images"},{"location":"glossary/mark-down/#tables","text":"Tables aren't part of the core Markdown spec, but they are part of GFM and Markdown Here supports them. They are an easy way of adding tables to your email -- a task that would otherwise require copy-pasting from another application. Colons can be used to align columns. | Tables | Are | Cool | | ------------- |:-------------:| -----:| | col 3 is | right-aligned | $1600 | | col 2 is | centered | $12 | | zebra stripes | are neat | $1 | There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown | Less | Pretty --- | --- | --- *Still* | `renders` | **nicely** 1 | 2 | 3 ... becomes ... Colons can be used to align columns. Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 There must be at least 3 dashes separating each header cell. The outer pipes ( | ) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown. Markdown Less Pretty Still renders nicely 1 2 3","title":"Tables"},{"location":"glossary/mark-down/#blockquotes","text":"> Blockquotes are very handy in email to emulate reply text. > This line is part of the same quote. Quote break. > This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can *put* **Markdown** into a blockquote. becomes: Blockquotes are very handy in email to emulate reply text. This line is part of the same quote. Quote break. This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can put Markdown into a blockquote.","title":"Blockquotes"},{"location":"glossary/mark-down/#inline-html","text":"You can also use raw HTML in your Markdown, and it'll mostly work pretty well. <dl> <dt>Definition list</dt> <dd>Is something people use sometimes.</dd> <dt>Markdown in HTML</dt> <dd>Does *not* work **very** well. Use HTML <em>tags</em>.</dd> </dl> Definition list Is something people use sometimes. Markdown in HTML Does *not* work **very** well. Use HTML tags .","title":"Inline HTML"},{"location":"glossary/mark-down/#horizontal-rule","text":"Three or more... --- Hyphens ... becomes ... Hyphens","title":"Horizontal Rule"},{"location":"glossary/mark-down/#line-breaks","text":"My basic recommendation for learning how line breaks work is to experiment and discover -- hit <Enter> once (i.e., insert one newline), then hit it twice (i.e., insert two newlines), see what happens. You'll soon learn to get what you want. \"Markdown Toggle\" is your friend. Here are some things to try out: Here's a line for us to start with. This line is separated from the one above by two newlines, so it will be a *separate paragraph* . This line is also a separate paragraph, but... This line is only separated by a single newline, so it's a separate line in the *same paragraph* . Here's a line for us to start with. This line is separated from the one above by two newlines, so it will be a separate paragraph . This line is also begins a separate paragraph, but... This line is only separated by a single newline, so it's a separate line in the same paragraph .","title":"Line Breaks"},{"location":"glossary/working-with-github/","text":"This guide is written with the team in mind. The majority of our projects are narrowly-focused to solving customer problems, such as Cisco Refresh or KPOM, and this set of best practices reflects that. These are a lot of lessons learned from working on large opensource projects such as Orchard Core, that influence this approach, but it is recognised that (much like in client project management) different projects come with different needs and no single set of tools or methodologies can be universally applied. Important The following items should be required across all repositories managed by our team. By keeping the same experience across all our repositories, it makes it easier for B Skwad and external contributors to work within any repository and operate with the same assumptions as any other B Skwad repository. Documentation Maintain project documentation within the repository, in a ./docs subfolder. This keeps everything portable and usable even when offline. There are two main varieties of documentation typically associated with open source software: usage instructions and maintenance guidelines. Most of this section focuses on maintenance guidelines to support the process you\u2019ve outlined, as usage instructions will vary widely between projects. Tip Documentation associated with B Skwad projects should be hosted using GitHub Pages, by writing markdown files in the ./docs subfolder. Which will be automatically built and pushed to a gh-pages branch that deploys to our GitHub Pages site, on a successful merge to master . Code coverage Every feature should be accompanied with tests and all pull requests should come with associated tests, all living within a tests directory. While we have no intention of striving for 100% code coverage, we should aim for above 80% with above 90% being the ideal. We should also look to utilise a code coverage / automated code review tool like Codecov and ensure that is a pull request requirement before merging. Issue and PR labels The following labels should be our standard set of labels across all repositories to help ensure we use clear and consistent labelling terminology. This will allow us to see the status and type of all issues at a glance, to help track and report on contributions across our repositories, and to provide easier ways to find issues to contribute to (e.g., all needs:ux and good-first-issues). We\u2019re starting a minimal set of labels and will let progressive enhancement further define them for us as well as perform occasional housekeeping. type:bug - \u201cSomething isn\u2019t working.\u201d (color: #d73a4a) type:enhancement - \u201cNew feature or request.\u201d (color: #a2eeef) type:invalid - \u201cThis doesn't seem right.\u201d (color: #993299) type:question - \u201cFurther information is requested.\u201d (color: #d876e3) type:wont-fix - \u201cThis issue or pull request already exists.\u201d (color: #d876e3) needs:code-review - \u201cThis requires code review.\u201d (color: #999999) needs:design - \u201cThis requires design to resolve.\u201d (color: #999999) needs:documentation - \u201cThis requires documentation.\u201d (color: #999999) needs:feedback - \u201cThis requires feedback to determine next steps.\u201d (color: #999999) needs:refresh - \u201cThis requires a refreshed PR to resolve.\u201d (color: #999999) needs:tests - \u201cThis requires tests.\u201d (color: #999999) resolution:not-applicable - \u201cWe do not feel this issue is valid.\u201d (color: #FFA500) resolution:not-reproducible - \u201cWe are unable to reproduce this issue.\u201d (color: #FFFF00) resolution:resolved - \u201cThis issue has been resolved.\u201d (color: #008000) resolution:postfix - \u201cWe do not intend to resolve this issue.\u201d (color: #000000) Workflows Standardising on a workflow is an important part of the development process. Utilising an effective workflow ensures efficient collaboration and quicker project onboarding. For this reason, we will be using GitFlow . Commits Commits should be small and independent items of work, containing changes limited to a distinct idea. Distinct commits are essential in keeping features separate, pushing specific features forward, or reversing or rolling back code if necessary. Commit Messages The first line of a commit message is a brief summary of the changeset, describing the expected result of the change or what is done to affect change. git log --oneline -5 # fca8925 Update commit message best practices # 19188a0 Add a note about autoloading transients # 9630552 Fix a typo in apply_mtu/task.yml # 2309e04 Remove extra markdown header hash # 5cd2604 Add h3 and h4 styling to README.md This brief summary is always required. It is around 50 characters or less, always stopping at 70. The high visibility of the first line makes it critical to craft something that is as descriptive as possible within space limits. And example is given below. git commit -m \"Add an eos module to support MTU\" Protecting the master Branch All repositories are to be configured so the master branch is protected to prevent direct pushes. All merges should be made through a pull request, which ensures all code changes are peer reviewed before merging to prevent unintentional code reversions. Additionally, protecting branches provides the following benefits: Prevents the master branch from being accidentally deleted by other engineers Prevents force-pushes to the branch, overwriting the history New Development The master branch represents a stable, released, versioned product. Ongoing development will happen in feature branches branched off a develop branch, which is itself branched off master . All new features will treat the develop branch as the canonical source. Feature branches will branch off develop and should always have develop merged back into them before requesting peer code review and before deploying to any staging environments. This pattern is commonly referred to as the GitFlow . Semantic Versioning As we assign version numbers to our software, we follow the Semantic Versioning pattern, wherein each version follows a MAJOR.MINOR.PATCH scheme: MAJOR versions are incremented when breaking changes are introduced, such as functionality being removed or otherwise major changes to the codebase. MINOR versions are incremented when new functionality is added in a backwards-compatible manner. PATCH versions are incremented for backwards-compatible bugfixes. Imagine Erik has written a new zone parser: parse_zone . He might give his first public release version 1.0.0. After releasing the module, Erik decides to add some new (backwards-compatible) features, and subsequently releases version 1.1.0 . Later, Christi finds a bug and reports it to Erik via a GitHub Issue ; no functionality is added or removed, but Erik fixes the bug and releases version 1.1.1 . Down the road, Erik decides to remove some functionality or change the way some functions are used. Since this would change how others interact with his code, he would declare this new release to be version 2.0.0 , hinting to consumers that there are breaking changes in the new version of his module. Deleting or Archiving and Deleting Branches This workflow will inevitably build up a large list of branches in the repository. To prevent a large number of unused branches living in the repository, we\u2019ll delete or archive and delete them after feature development is complete. Deleting branches When projects use non-ff merges to master , we can safely delete feature branches because all commits are preserved and can be located from the merge commit. Move to another branch (doesn\u2019t matter which): eg. git checkout master Delete the branch (both on local and remote): git branch -D branch-name; git push :branch-name","title":"Working With GitHub"},{"location":"glossary/working-with-github/#documentation","text":"Maintain project documentation within the repository, in a ./docs subfolder. This keeps everything portable and usable even when offline. There are two main varieties of documentation typically associated with open source software: usage instructions and maintenance guidelines. Most of this section focuses on maintenance guidelines to support the process you\u2019ve outlined, as usage instructions will vary widely between projects. Tip Documentation associated with B Skwad projects should be hosted using GitHub Pages, by writing markdown files in the ./docs subfolder. Which will be automatically built and pushed to a gh-pages branch that deploys to our GitHub Pages site, on a successful merge to master .","title":"Documentation"},{"location":"glossary/working-with-github/#code-coverage","text":"Every feature should be accompanied with tests and all pull requests should come with associated tests, all living within a tests directory. While we have no intention of striving for 100% code coverage, we should aim for above 80% with above 90% being the ideal. We should also look to utilise a code coverage / automated code review tool like Codecov and ensure that is a pull request requirement before merging.","title":"Code coverage"},{"location":"glossary/working-with-github/#issue-and-pr-labels","text":"The following labels should be our standard set of labels across all repositories to help ensure we use clear and consistent labelling terminology. This will allow us to see the status and type of all issues at a glance, to help track and report on contributions across our repositories, and to provide easier ways to find issues to contribute to (e.g., all needs:ux and good-first-issues). We\u2019re starting a minimal set of labels and will let progressive enhancement further define them for us as well as perform occasional housekeeping. type:bug - \u201cSomething isn\u2019t working.\u201d (color: #d73a4a) type:enhancement - \u201cNew feature or request.\u201d (color: #a2eeef) type:invalid - \u201cThis doesn't seem right.\u201d (color: #993299) type:question - \u201cFurther information is requested.\u201d (color: #d876e3) type:wont-fix - \u201cThis issue or pull request already exists.\u201d (color: #d876e3) needs:code-review - \u201cThis requires code review.\u201d (color: #999999) needs:design - \u201cThis requires design to resolve.\u201d (color: #999999) needs:documentation - \u201cThis requires documentation.\u201d (color: #999999) needs:feedback - \u201cThis requires feedback to determine next steps.\u201d (color: #999999) needs:refresh - \u201cThis requires a refreshed PR to resolve.\u201d (color: #999999) needs:tests - \u201cThis requires tests.\u201d (color: #999999) resolution:not-applicable - \u201cWe do not feel this issue is valid.\u201d (color: #FFA500) resolution:not-reproducible - \u201cWe are unable to reproduce this issue.\u201d (color: #FFFF00) resolution:resolved - \u201cThis issue has been resolved.\u201d (color: #008000) resolution:postfix - \u201cWe do not intend to resolve this issue.\u201d (color: #000000)","title":"Issue and PR labels"},{"location":"glossary/working-with-github/#workflows","text":"Standardising on a workflow is an important part of the development process. Utilising an effective workflow ensures efficient collaboration and quicker project onboarding. For this reason, we will be using GitFlow .","title":"Workflows"},{"location":"glossary/working-with-github/#commits","text":"Commits should be small and independent items of work, containing changes limited to a distinct idea. Distinct commits are essential in keeping features separate, pushing specific features forward, or reversing or rolling back code if necessary.","title":"Commits"},{"location":"glossary/working-with-github/#commit-messages","text":"The first line of a commit message is a brief summary of the changeset, describing the expected result of the change or what is done to affect change. git log --oneline -5 # fca8925 Update commit message best practices # 19188a0 Add a note about autoloading transients # 9630552 Fix a typo in apply_mtu/task.yml # 2309e04 Remove extra markdown header hash # 5cd2604 Add h3 and h4 styling to README.md This brief summary is always required. It is around 50 characters or less, always stopping at 70. The high visibility of the first line makes it critical to craft something that is as descriptive as possible within space limits. And example is given below. git commit -m \"Add an eos module to support MTU\"","title":"Commit Messages"},{"location":"glossary/working-with-github/#protecting-the-master-branch","text":"All repositories are to be configured so the master branch is protected to prevent direct pushes. All merges should be made through a pull request, which ensures all code changes are peer reviewed before merging to prevent unintentional code reversions. Additionally, protecting branches provides the following benefits: Prevents the master branch from being accidentally deleted by other engineers Prevents force-pushes to the branch, overwriting the history","title":"Protecting the master Branch"},{"location":"glossary/working-with-github/#new-development","text":"The master branch represents a stable, released, versioned product. Ongoing development will happen in feature branches branched off a develop branch, which is itself branched off master . All new features will treat the develop branch as the canonical source. Feature branches will branch off develop and should always have develop merged back into them before requesting peer code review and before deploying to any staging environments. This pattern is commonly referred to as the GitFlow .","title":"New Development"},{"location":"glossary/working-with-github/#semantic-versioning","text":"As we assign version numbers to our software, we follow the Semantic Versioning pattern, wherein each version follows a MAJOR.MINOR.PATCH scheme: MAJOR versions are incremented when breaking changes are introduced, such as functionality being removed or otherwise major changes to the codebase. MINOR versions are incremented when new functionality is added in a backwards-compatible manner. PATCH versions are incremented for backwards-compatible bugfixes. Imagine Erik has written a new zone parser: parse_zone . He might give his first public release version 1.0.0. After releasing the module, Erik decides to add some new (backwards-compatible) features, and subsequently releases version 1.1.0 . Later, Christi finds a bug and reports it to Erik via a GitHub Issue ; no functionality is added or removed, but Erik fixes the bug and releases version 1.1.1 . Down the road, Erik decides to remove some functionality or change the way some functions are used. Since this would change how others interact with his code, he would declare this new release to be version 2.0.0 , hinting to consumers that there are breaking changes in the new version of his module.","title":"Semantic Versioning"},{"location":"glossary/working-with-github/#deleting-or-archiving-and-deleting-branches","text":"This workflow will inevitably build up a large list of branches in the repository. To prevent a large number of unused branches living in the repository, we\u2019ll delete or archive and delete them after feature development is complete.","title":"Deleting or Archiving and Deleting Branches"},{"location":"glossary/working-with-github/#deleting-branches","text":"When projects use non-ff merges to master , we can safely delete feature branches because all commits are preserved and can be located from the merge commit. Move to another branch (doesn\u2019t matter which): eg. git checkout master Delete the branch (both on local and remote): git branch -D branch-name; git push :branch-name","title":"Deleting branches"},{"location":"usage/cloning-the-repo/","text":"On GitHub, navigate to the main page of the repository . Under the repository name, click green Code button. To clone the repository, click Use SSH, then click the copy button . Open a Ubuntu\u2122 Terminal, and create a new filesystem in ~/dev/apps/ , change the current working directory to the ~/dev/apps/ directory, and clone the repository from GitHub. me@my-pc ~$ mkdir -p ~/dev/apps me@my-pc ~$ cd ~/dev/apps me@my-pc ~/dev/apps$ git clone git@github.com:b-skwad/duckview.git Cloning into 'duckview' ... remote: Enumerating objects: 20 , done . remote: Counting objects: 100 % ( 20 /20 ) , done . remote: Compressing objects: 100 % ( 18 /18 ) , done . remote: Total 20 ( delta 0 ) , reused 0 ( delta 0 ) , pack-reused 0 Receiving objects: 100 % ( 20 /20 ) , 6 .04 KiB | 3 .02 MiB/s, done . Change into the new file system ~/dev/apps/duckview , and validate connectivity back to the duckview GitHub repository. me@my-pc ~/dev/apps$ cd duckview me@my-pc ~/dev/apps/duckview$ git remote -v origin git@github.com:b-skwad/duckview.git ( fetch ) origin git@github.com:b-skwad/duckview.git ( push ) me@my-pc ~/dev/apps/duckview$ The repository has been cloned and can now see the GitHub Repo as a remote origin . Steps 4, 5, and 6 can be repeated on any computer that has been configured to work with GitHub.","title":"Cloning the Repository"},{"location":"usage/opening-the-project/","text":"In this example, we are working with the duckview example project. Opening the project in Visual Studio Code for the first time Open your Ubuntu\u2122 Terminal and navigate to the project folder ~/dev/apps/duckview . Then type code . to open the project. me@my-pc ~$ cd ~/dev/apps/duckview me@my-pc ~/dev/apps/duckview$ code . me@my-pc ~/dev/apps/duckview$ The project will load in VSC. Starting the Development Container Once loaded, click on the small green Icon on the bottom left hand corner of the Visual Studio Code. This will make the remote select dropdown appear. Chose Remote-Containers: Reopen in Container . The project will now open in the development docker container. The green icon will switch from to saying Opening Remote... . The first time opening this container on your machine will take a while, as the required development images need to be downloaded from Docker Hub, to build the container. I suggest a coffee, or maybe a 15 nap. The container will be fully loaded and ready to use when the icon in the bottom left switches from Opening Remote to Dev Container: F\u2734\u2734\u2734 Parser as shown. We can now test that the container is up and running by opening a terminal within VSC. To open a new terminal in VSCode on Windows, press Ctrl + Shift + ' or Ctrl + ' The command prompt of the new terminal will read: \u256d\u2500vscode@duckview /app \u2039develop\u203a \u2570\u2500\u27a4 <develop> references your current git branch. This is the branch from which you will create feature branches. Closing the project In the menu-bar, click File -> Close Remote Connection , this stops the development container. You can now close Visual Studio Code. Re-opening the project After you have opened the project for the first time, subsequent opening is simply done by clicking File -> Open Recent then clicking on /home/<your name>/dev/apps/duckview [WSL] Ensure that [WSL] at the end of the folder name. Then restart the development container, as normal.","title":"Opening the Project"},{"location":"usage/opening-the-project/#opening-the-project-in-visual-studio-code-for-the-first-time","text":"Open your Ubuntu\u2122 Terminal and navigate to the project folder ~/dev/apps/duckview . Then type code . to open the project. me@my-pc ~$ cd ~/dev/apps/duckview me@my-pc ~/dev/apps/duckview$ code . me@my-pc ~/dev/apps/duckview$ The project will load in VSC.","title":"Opening the project in Visual Studio Code for the first time"},{"location":"usage/opening-the-project/#starting-the-development-container","text":"Once loaded, click on the small green Icon on the bottom left hand corner of the Visual Studio Code. This will make the remote select dropdown appear. Chose Remote-Containers: Reopen in Container . The project will now open in the development docker container. The green icon will switch from to saying Opening Remote... . The first time opening this container on your machine will take a while, as the required development images need to be downloaded from Docker Hub, to build the container. I suggest a coffee, or maybe a 15 nap. The container will be fully loaded and ready to use when the icon in the bottom left switches from Opening Remote to Dev Container: F\u2734\u2734\u2734 Parser as shown. We can now test that the container is up and running by opening a terminal within VSC. To open a new terminal in VSCode on Windows, press Ctrl + Shift + ' or Ctrl + ' The command prompt of the new terminal will read: \u256d\u2500vscode@duckview /app \u2039develop\u203a \u2570\u2500\u27a4 <develop> references your current git branch. This is the branch from which you will create feature branches.","title":"Starting the Development Container"},{"location":"usage/opening-the-project/#closing-the-project","text":"In the menu-bar, click File -> Close Remote Connection , this stops the development container. You can now close Visual Studio Code.","title":"Closing the project"},{"location":"usage/opening-the-project/#re-opening-the-project","text":"After you have opened the project for the first time, subsequent opening is simply done by clicking File -> Open Recent then clicking on /home/<your name>/dev/apps/duckview [WSL] Ensure that [WSL] at the end of the folder name. Then restart the development container, as normal.","title":"Re-opening the project"}]}